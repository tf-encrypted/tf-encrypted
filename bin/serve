#!/usr/bin/env python

import sys
import os
import uuid
import time
import re
import argparse
from pathlib import Path
from urllib import request as urlDownloader
from threading import Thread
from typing import Dict, Any, Tuple, Callable, List

import tensorflow as tf
from tensorflow.python.platform import gfile
import numpy as np
from flask import Flask, request, jsonify  # type: ignore
from flask_cors import CORS  # type: ignore

import tensorflow_encrypted as tfe

node_name = os.environ.get('TFE_NODE_NAME')
server0_address = os.environ.get('TFE_SERVER0_ADDRESS')
server1_address = os.environ.get('TFE_SERVER1_ADDRESS')
producer_address = os.environ.get('TFE_CRYPTO_PRODUCER_ADDRESS')
provider_address = os.environ.get('TFE_WEIGHTS_PROVIDER_ADDRESS')
master_address = os.environ.get('TFE_MASTER_ADDRESS')
port = int(os.environ.get('TFE_API_PORT', "8080"))
enable_stats_monitor = os.environ.get('TFE_MONITOR_STATS') is not None
enable_debug = os.environ.get('TFE_DEBUG') is not None

if node_name is None:
    print("The node_name of this node must be provided via the 'TFE_NODE_NAME' environment variable")
    sys.exit(1)

if server0_address is None:
    print("The address for server 0 must be provided via the 'TFE_SERVER0_ADDRESS' environment variable")
    sys.exit(1)

if server1_address is None:
    print("The address for server 1 must be provided via the 'TFE_SERVER1_ADDRESS' environment variable")
    sys.exit(1)

if producer_address is None:
    print("The address for the producer must be provided via the 'TFE_CRYPTO_PRODUCER_ADRESS' environment variable")
    sys.exit(1)

if provider_address is None:
    print("The address for the weights provider must be provided via the 'TFE_WEIGHTS_PROVIDER_ADDRESS' environment variable")
    sys.exit(1)

if master_address is None:
    print("The address for master must be provided via the 'TFE_MASTER_ADDRESS' environment variable")
    sys.exit(1)

tfe.setMonitorStatsFlag(enable_stats_monitor)
tfe.setTFEDebugFlag(enable_debug)

remote_config = tfe.RemoteConfig(
    {
        'master': master_address,
        'server0': server0_address,
        'server1': server1_address,
        'crypto_producer': producer_address,
        'weights_provider': provider_address
    },
    master='master'
)

server = remote_config.server(node_name)
if node_name != 'master':
    server.join()
else:
    _global_memory: Dict[str, Any] = {}

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--model_name", type=str, default='', help="Model name")
    parser.add_argument(
        "--model_url", type=str, default='', help="Model's public URL")
    config = parser.parse_args()

    model_file = os.path.join(
        os.path.dirname(os.path.realpath(__file__)),
        "..",
        "models",
        "{}.pb".format(config.model_name),
    )
    model_path = Path(model_file)
    if not model_path.is_file() and config.model_url is not '':
        regex = re.compile(
            r'^(?:http|ftp)s?://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE
        )
        if re.match(regex, config.model_url) is not None:
            print('Downloading model from URL: {}'.format(config.model_url))
            model_file, _ = urlDownloader.urlretrieve(config.model_url)
        else:
            raise Exception('Invalid URL given: {}'.format(config.model_url))

    tf.reset_default_graph()

    input_spec = []
    with gfile.FastGFile(model_file, 'rb') as f:
        print('Loading model: {}'.format(model_file))
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())

        for node in graph_def.node:
            if node.op != "Placeholder":
                continue

            input_spec.append({
                'name': node.name,
                'dtype': node.attr['dtype'].type,
                'shape': [int(d.size) if d.size > 0 else 1 for d in node.attr['shape'].shape.dim]
            })

    sess = remote_config.session()

    with tfe.protocol.Pond(*remote_config.get_players('server0, server1, crypto_producer')) as prot:
        assert isinstance(prot, tfe.protocol.Pond)

        inputs = []
        for i, spec in enumerate(input_spec):
            def scope(i: int) -> Callable[[], tf.Tensor]:
                def provide_input() -> tf.Tensor:
                    pl = tf.placeholder(tf.float32, shape=spec['shape'], name="api/{}".format(i))
                    return pl

                return provide_input

            x = tfe.io.InputProvider(remote_config.get_player('master'), scope(i))
            inputs.append(x)

        print('Securing computation')
        secure_start = time.time()

        c = tfe.convert.convert.Converter(remote_config, prot, remote_config.get_player('weights_provider'))
        y = c.convert(graph_def, inputs, tfe.convert.register())
        # TODO: do not reveal on the master server
        y = y.reveal()

        secure_end = time.time()
        print("Graph secured in {}".format(secure_end - secure_start))

        if isinstance(prot, tfe.protocol.Pond):
            print('Initializing variables')
            init_start = time.time()

            tfe.run(sess, prot.initializer, tag='init')

            init_end = time.time()
            print("Graph initialized in {}".format(init_end - init_start))

    pls = []
    for i in range(len(input_spec)):
        if i == 0:
            name = "private-input/api/{}:0".format(i)
        else:
            name = "private-input_{}/api/{}:0".format(i, i)
        pls.append(
            tf.get_default_graph().get_tensor_by_name(name)
        )

    def predict(request_id: str, input_data: List[Any]) -> None:
        feed_dict = {
            pl: input_data[i] for i, pl in enumerate(pls)
        }
        output_data = y.eval(
            sess=sess,
            feed_dict=feed_dict,
            tag='prediction',
        )

        _global_memory[request_id] = output_data[0].tolist()

    print("Warming up the graph")
    warmup_data = []
    for spec in input_spec:
        warmup_data.append(
            np.random.standard_normal(spec['shape']).tolist()
        )
    warmup_start = time.time()
    predict("warm-up-id", warmup_data)
    _global_memory.pop("warm-up-id")
    warmup_end = time.time()
    print("Graph warmed up in {}".format(warmup_end - warmup_start))

    print('Serving model: %s' % config.model_name)

    # define the app
    app = Flask(__name__)
    CORS(app)  # needed for cross-domain requests, allow everything by default

    @app.route('/input_spec')  # type: ignore
    def api_input_spec() -> str:
        return jsonify(input_spec)

    @app.route('/predict', methods=['POST'])  # type: ignore
    def api_predict() -> str:
        input_data = request.json
        app.logger.info("api_predict_input: " + str(input_data))

        request_id = str(uuid.uuid4())
        thread = Thread(target=predict, kwargs={
            'request_id': request_id,
            'input_data': input_data
        })
        thread.start()

        app.logger.info("api_predict_output: " + request_id)

        data = {'request_id': request_id}
        return jsonify(data)

    @app.route('/poll', methods=['POST'])  # type: ignore
    def api_poll() -> str:
        request_id = request.json
        app.logger.info("api_poll_input: " + str(request_id))

        output_data = _global_memory.pop(request_id, None)

        app.logger.info("api_poll_output: " + str(output_data))
        response = jsonify(output_data)
        return response

    @app.route('/')  # type: ignore
    def index() -> str:
        return "Welcome to PartyDB! An crypto-friendly production environment for serving machine learning models"

    # HTTP Errors handlers
    @app.errorhandler(404)  # type: ignore
    def url_error(e: str) -> Tuple[str, int]:
        return """
        Wrong URL!
        <pre>{}</pre>""".format(e), 404

    @app.errorhandler(500)  # type: ignore
    def server_error(e: str) -> Tuple[str, int]:
        return """
        An internal error occurred: <pre>{}</pre>
        See logs for full stacktrace.
        """.format(e), 500

    app.run(host='0.0.0.0', debug=True, use_reloader=False, port=port)
