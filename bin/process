#!/usr/bin/env python

import glob
import json
import argparse

import numpy as np

parser = argparse.ArgumentParser(description='Extract the average prediction\
                                    time with the specified trace directory')
parser.add_argument('trace_dir', type=str, help='Specify the trace directory')
args = parser.parse_args()

trace_dir = args.trace_dir
trace_path = trace_dir + "/*.ctr"


def parse_tracefile(filename):

    with open(filename, 'r') as f:
        raw = json.load(f)

    if 'traceEvents' not in raw:
        return None

    traceEvents = raw['traceEvents']

    timestamps = (
        (
            event['ts'],
            event['ts'] + event['dur']
        )
        for event in traceEvents
        if 'ts' in event and 'dur' in event
    )
    timestamps = sorted(timestamps, key=lambda x: x[1])

    min_ts = timestamps[0]
    max_ts = timestamps[-1]
    return max_ts[1] - min_ts[0]


durations = []

for filename in glob.glob(trace_path):
    # Exclude init0.ctr and prediction0.ctr as they don't reflect the real prediction time.
    if ("init0.ctr" not in filename) & ("prediction0.ctr" not in filename):
        duration = parse_tracefile(filename)
        durations.append(duration)

summary = """Summary statistics

Number of Predictions: {}
Average Prediction Time: {} ms
Median Prediction Time: {} ms
Standard Deviation Time: {} ms
Min Prediction Time: {} ms
Max Prediction Time: {} ms
""".format(
    len(durations),
    (float(sum(durations)) / len(durations)) / 1000,
    np.median(durations) / 1000,
    np.std(durations) / 1000,
    np.min(durations) / 1000,
    np.max(durations) / 1000
)

# Export duration for 100 predictions:
np.save('results.npy', durations)
print(summary)

with open("summary.txt", "w") as summary_file:
    summary_file.write(summary)
